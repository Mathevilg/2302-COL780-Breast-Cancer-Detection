{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch.cuda, torch.utils.data, torch.nn, torch.optim, torch\n",
    "import torchvision.transforms, torchvision.datasets.folder, torchvision.utils, torchvision.models\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addresses\n",
    "\n",
    "class Address:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Stores all the addresses used in project\n",
    "        '''\n",
    "        # Inputs\n",
    "        self.data = \"../input/mammography\"\n",
    "        self.processed_data = \"data.pkl\"\n",
    "\n",
    "        # Coco\n",
    "        self.coco = os.path.join(self.data, 'coco_1k')\n",
    "        self.coco_annot = os.path.join(self.coco, 'annotations')\n",
    "        self.coco_annot_train = os.path.join(self.coco_annot, 'instances_train2017.json')\n",
    "        self.coco_annot_val = os.path.join(self.coco_annot, 'instances_val2017.json')\n",
    "        self.coco_img_train = os.path.join(self.coco, 'train2017')\n",
    "        self.coco_img_val = os.path.join(self.coco, 'val2017')\n",
    "\n",
    "        # Test\n",
    "        self.test = os.path.join(self.data, 'test')\n",
    "        self.test_img = os.path.join(self.test, 'images')\n",
    "        self.test_label = os.path.join(self.test, 'labels')\n",
    "        self.predictions = os.path.join(self.test, 'predictions')\n",
    "\n",
    "        # Yolo\n",
    "        self.yolo = os.path.join(self.data, 'yolo_1k')\n",
    "        self.yolo_train = os.path.join(self.yolo, 'train')\n",
    "        self.yolo_train_img = os.path.join(self.yolo_train, 'images')\n",
    "        self.yolo_train_label = os.path.join(self.yolo_train, 'labels')\n",
    "        self.yolo_val = os.path.join(self.yolo, 'val')\n",
    "        self.yolo_val_img = os.path.join(self.yolo_val, 'images')\n",
    "        self.yolo_val_labels = os.path.join(self.yolo_val, 'labels')\n",
    "\n",
    "        # Models\n",
    "        self.result = \"results/\"\n",
    "        self.model_frcnn = os.path.join(self.result, 'frcnn')\n",
    "\n",
    "        # Temp\n",
    "        self.temp = \"temp/\"\n",
    "\n",
    "    def create_dir(self, dir_list = None):\n",
    "        '''\n",
    "        Function to create directories in dir_list. If dir_list is None then create all directories of address.\n",
    "        '''\n",
    "        if dir_list == None:\n",
    "            dir_list = [self.temp, self.result, self.model_frcnn]\n",
    "        for address in dir_list:\n",
    "            if not os.path.exists(address):\n",
    "                os.mkdir(address)\n",
    "\n",
    "    def _delete_folder_content(self, folder_addr):\n",
    "        '''\n",
    "        Deletes all the content of folder_addr\n",
    "        '''\n",
    "        if os.path.exists(folder_addr):\n",
    "            for file in os.listdir(folder_addr):\n",
    "                address = os.path.join(folder_addr, file)\n",
    "                if os.path.isdir(address):\n",
    "                    self._delete_folder_content(address)\n",
    "                    os.removedirs(address)\n",
    "                else:\n",
    "                    os.remove(address)\n",
    "\n",
    "    def clean(self, file_list = None):\n",
    "        '''\n",
    "        Deletes all the content in file_list\n",
    "        '''\n",
    "        if file_list == None:\n",
    "            file_list = [self.temp]\n",
    "        for address in file_list:\n",
    "            self._delete_folder_content(address)\n",
    "\n",
    "addr = Address()\n",
    "addr.clean()\n",
    "addr.create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Stores all Hyperparameters used for training of model\n",
    "        '''\n",
    "        # Training\n",
    "        self.batch_size = 2\n",
    "        self.num_epoch = 10\n",
    "        self.grad_clip = 1.0\n",
    "\n",
    "        # Data\n",
    "        self.num_train = 40000\n",
    "        self.num_val = 10000\n",
    "        self.train_step = self.num_epoch*(self.num_train//self.batch_size)\n",
    "        self.resolution = (512, 1024)\n",
    "        \n",
    "        # Learning Rate\n",
    "        self.lr = 1e-5\n",
    "        self.warmup_step = self.train_step//40\n",
    "        self.decay_step = self.train_step//2\n",
    "        self.decay_rate = 0.5\n",
    "\n",
    "    def lr_schedule(self, step):\n",
    "        '''\n",
    "        Getting learning rate as function of train steps completed (Exponential decay with linear warmup)\n",
    "        '''\n",
    "        if step <= self.warmup_step:\n",
    "            return step/self.warmup_step\n",
    "        else:\n",
    "            return self.decay_rate**((step-self.warmup_step)/self.decay_step)\n",
    "\n",
    "    def create_report(self, addr):\n",
    "        with open(os.path.join(addr, 'param.txt'), 'w') as file:\n",
    "            file.writelines([\n",
    "                f'Training:',\n",
    "                f'\\n\\tBatch Size:       {self.batch_size}',\n",
    "                f'\\n\\tNum Epoch:        {self.num_epoch}',\n",
    "                f'\\n\\tGrad Clip:        {self.grad_clip}',\n",
    "                f'\\n\\nData:',  \n",
    "                f'\\n\\tNum Train:        {self.num_train}',\n",
    "                f'\\n\\tNum Val:          {self.num_val}',\n",
    "                f'\\n\\tTrain Step:       {self.train_step}',\n",
    "                f'\\n\\tResolution:       {self.resolution}',\n",
    "                f'\\n\\nLearning Rate:',  \n",
    "                f'\\n\\tlr:               {self.lr}',\n",
    "                f'\\n\\tWarmup Step:      {self.warmup_step}',\n",
    "                f'\\n\\tDecay Step:       {self.decay_step}',\n",
    "                f'\\n\\tDecay Rate:       {self.decay_rate}',\n",
    "            ])\n",
    "\n",
    "param = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with device cpu\n"
     ]
    }
   ],
   "source": [
    "# Random Seed and CUDA\n",
    "\n",
    "random_seed = 68\n",
    "device = \"cpu\"\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed_all(random_seed)\n",
    "#     device = \"cuda\"\n",
    "print(f\"Working with device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, resolution, address_img, address_annot=None):\n",
    "        '''\n",
    "        Creates Dataset of images on given address.\n",
    "        '''\n",
    "        self.address_img = address_img\n",
    "        self.resolution = resolution\n",
    "        self.img_list = sorted(os.listdir(self.address_img))\n",
    "        self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                        torchvision.transforms.Resize(resolution, antialias=False)])\n",
    "        self.img_list = None\n",
    "        self.img_name_list = sorted(os.listdir(self.address_img))\n",
    "        with open(address_annot, 'rb') as file:\n",
    "            self.annotation = json.load(file)\n",
    "        self.beautify()\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.img_list is None:\n",
    "            return len(os.listdir(self.address_img))\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.img_list is None:\n",
    "            img_addr = os.path.join(self.address_img, self.img_name_list[idx])\n",
    "            img = torchvision.datasets.folder.default_loader(img_addr)\n",
    "            return self.transform(img).to(torch.float), self.annotation[idx]\n",
    "        return self.img_list[idx], self.annotation[idx]\n",
    "    \n",
    "    def load(self):\n",
    "        '''\n",
    "        Loads all the data in RAM\n",
    "        '''\n",
    "        if self.img_list is not None:\n",
    "            return\n",
    "        self.img_list = [self[idx][0] for idx in range(len(self))]\n",
    "\n",
    "    def clean(self):\n",
    "        '''\n",
    "        Removes Data from RAM\n",
    "        '''\n",
    "        del self.img_list\n",
    "        self.img_list = None\n",
    "\n",
    "    def beautify(self):\n",
    "        '''\n",
    "        Removes Redundant data from json file\n",
    "        '''\n",
    "        label_data = {}\n",
    "        for img_data in self.annotation['images']:\n",
    "            label_data[img_data['id']] = img_data\n",
    "            label_data[img_data['id']]['bbox'] = []\n",
    "        for img_data in self.annotation['annotations']:\n",
    "            label_data[img_data['id']]['bbox'].append(img_data['bbox'])\n",
    "            img_data['bbox'][2] += img_data['bbox'][0]\n",
    "            img_data['bbox'][3] += img_data['bbox'][1]\n",
    "            img_data['bbox'][0] = img_data['bbox'][0]*self.resolution[0]/label_data[img_data['id']]['width']\n",
    "            img_data['bbox'][1] = img_data['bbox'][1]*self.resolution[1]/label_data[img_data['id']]['height']\n",
    "            img_data['bbox'][2] = img_data['bbox'][2]*self.resolution[0]/label_data[img_data['id']]['width']\n",
    "            img_data['bbox'][3] = img_data['bbox'][3]*self.resolution[1]/label_data[img_data['id']]['height']\n",
    "        self.annotation = sorted(label_data.values(), key = lambda data: data['file_name'])\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, address: Address, param: HyperParameters):\n",
    "        '''\n",
    "        Creates DataLoader and DataSet for both train and val split\n",
    "        '''\n",
    "        self.address = address\n",
    "        self.param = param\n",
    "\n",
    "        # Dataset\n",
    "        self.dataset_train = DataSet(param.resolution, address.coco_img_train, address.coco_annot_train)\n",
    "        self.dataset_val = DataSet(param.resolution, address.coco_img_val, address.coco_annot_val)\n",
    "\n",
    "        # DataLoader\n",
    "        self.loader_train = torch.utils.data.DataLoader(self.dataset_train, batch_size=param.batch_size, collate_fn=self.collate, shuffle=True)\n",
    "        self.loader_val = torch.utils.data.DataLoader(self.dataset_val, batch_size=param.batch_size, collate_fn=self.collate, shuffle=False)\n",
    "    \n",
    "    def collate(self, batch):\n",
    "        label = []\n",
    "        img = []\n",
    "        for elem in batch:\n",
    "            img.append(elem[0].to(device))\n",
    "            if elem[1]['bbox']:\n",
    "                label_elem = {'boxes': torch.tensor(elem[1]['bbox'], dtype=torch.float, device=device), \n",
    "                              'labels': torch.tensor([0]*len(elem[1]['bbox']), dtype=torch.int64, device=device)}\n",
    "            else:\n",
    "                label_elem = {'boxes': torch.tensor([], dtype=torch.float, device=device).reshape(0, 4),\n",
    "                              'labels': torch.tensor([], dtype=torch.int64, device=device).reshape(0)}\n",
    "            label.append(label_elem)\n",
    "    \n",
    "        return img, label\n",
    "\n",
    "    def load(self):\n",
    "        '''\n",
    "        Loads all the data in RAM\n",
    "        '''\n",
    "        start_time = time.time()\n",
    "        self.dataset_train.load()\n",
    "        self.dataset_val.load()\n",
    "        print('Data Loaded in time:', time.time()-start_time)\n",
    "\n",
    "    def clean(self):\n",
    "        '''\n",
    "        Loads all the data in RAM\n",
    "        '''\n",
    "        self.dataset_train.clean()\n",
    "        self.dataset_val.clean()\n",
    "\n",
    "data = Data(addr, param)\n",
    "# data.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Model\n",
    "class LearnModel:\n",
    "    def __init__(self, model: torch.nn.Module, mtype, model_addr, data=data, param=param, device=device):\n",
    "        '''\n",
    "        Train, Evaluate and Predict\n",
    "        '''\n",
    "        \n",
    "        self.data = data\n",
    "        self.param = param\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.model_addr = model_addr\n",
    "        self.mtype = mtype\n",
    "\n",
    "        # Addresses\n",
    "        self.loss_addr = os.path.join(self.model_addr, 'loss.npz')\n",
    "        self.epoch_addr = lambda epoch: os.path.join(self.model_addr, f'model/{epoch}.pth')\n",
    "        self.scheduler_addr = lambda epoch: os.path.join(self.model_addr, f'scheduler/{epoch}.pth')\n",
    "        addr.create_dir([os.path.join(self.model_addr, 'model'),\n",
    "                         os.path.join(self.model_addr, 'scheduler')])\n",
    "\n",
    "    def train(self, epoch_log = True, batch_log = True, overwrite = False):\n",
    "        optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.param.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = self.param.lr_schedule)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Loss arr\n",
    "        if os.path.exists(self.loss_addr):\n",
    "            loss_arr = np.load(self.loss_addr)\n",
    "            train_loss_arr = list(loss_arr['train'])\n",
    "            val_loss_arr = list(loss_arr['val'])\n",
    "        else:\n",
    "            train_loss_arr = []\n",
    "            val_loss_arr = []\n",
    "\n",
    "        if overwrite:\n",
    "            addr.clean([self.model_addr])\n",
    "        \n",
    "        for epoch in range(self.param.num_epoch):\n",
    "            epoch_addr = self.epoch_addr(epoch)\n",
    "            scheduler_addr = self.scheduler_addr(epoch)\n",
    "\n",
    "            # Loading Model if present\n",
    "            if os.path.exists(epoch_addr) and os.path.exists(scheduler_addr):\n",
    "                self.model.load_state_dict(torch.load(epoch_addr), strict=False)\n",
    "                scheduler.load_state_dict(torch.load(scheduler_addr))\n",
    "                print(f\"Loaded model and scheduler at epoch {epoch}\")\n",
    "                continue\n",
    "\n",
    "            # Training Model\n",
    "            train_loss = self.train_epoch(optimizer, scheduler, batch_log=batch_log)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Validating Model\n",
    "            val_loss = self.validate_epoch(self.data.loader_val, batch_log=False)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tVal Loss: {val_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Saving data\n",
    "            train_loss_arr.append(train_loss)\n",
    "            val_loss_arr.append(val_loss)\n",
    "            np.savez_compressed(self.loss_addr, train=np.array(train_loss_arr), val=np.array(val_loss_arr))     # Saving Loss Array\n",
    "            torch.save(self.model.state_dict(), epoch_addr)     # Saving Model\n",
    "            torch.save(scheduler.state_dict(), scheduler_addr)  # Saving Scheduler\n",
    "\n",
    "            # Printing blank line between each epoch in Log\n",
    "            if epoch_log:\n",
    "                print()\n",
    "        \n",
    "    def train_epoch(self, optimizer, scheduler, batch_log):\n",
    "        '''\n",
    "        Trains model for one epoch\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        dataloader = self.data.loader_train\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.train()          # Set Model to train Mode\n",
    "\n",
    "        for data in dataloader:\n",
    "            # Copying data to cuda\n",
    "            x, y = data\n",
    "\n",
    "            # Forward Propagation\n",
    "            loss_dict = self.model(x, y)\n",
    "\n",
    "            # Computing Loss\n",
    "            loss = sum(loss_dict.values())\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Back Propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.param.grad_clip)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update batch count\n",
    "            batch_ct += 1\n",
    "\n",
    "            if batch_log and batch_ct%25 == 0:\n",
    "                print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "    \n",
    "    def validate_epoch(self, dataloader, batch_log):\n",
    "        '''\n",
    "        Calculates Loss on data in given dataloader\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.eval()           # Set Model to eval mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Copying data to cuda\n",
    "                x, y = data\n",
    "\n",
    "                # Forward Propagation\n",
    "                output_dict = self.model(x)\n",
    "\n",
    "                # Update batch count\n",
    "                batch_ct += 1\n",
    "\n",
    "                if batch_log and batch_ct%25 == 0:\n",
    "                    print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "\n",
    "    def plot_loss(self, addr = None):\n",
    "        '''\n",
    "        Plots Loss vs number of epochs\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        train_arr, val_arr = loss_arr['train'], loss_arr['val']\n",
    "        num_epoch = train_arr.shape[0]\n",
    "        x_arr = np.linspace(1, num_epoch, num_epoch)\n",
    "\n",
    "        if addr is None:\n",
    "            addr = os.path.join(self.model_addr, 'loss_curve')\n",
    "\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"MSE Loss\")\n",
    "        plt.plot(x_arr, train_arr, label='Train')\n",
    "        plt.plot(x_arr, val_arr, label='Val')\n",
    "        plt.legend()\n",
    "        plt.savefig(addr)\n",
    "\n",
    "    def best_model(self):\n",
    "        '''\n",
    "        Returns Best Model as well as changes self.model in place to best model\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        best_epoch = np.argmin(loss_arr['val'])\n",
    "        self.model.load_state_dict(torch.load(self.epoch_addr(best_epoch)), strict=False)\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m learner_conv \u001b[38;5;241m=\u001b[39m LearnModel(model_conv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrcnn\u001b[39m\u001b[38;5;124m'\u001b[39m, addr\u001b[38;5;241m.\u001b[39mmodel_frcnn, data, param, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      6\u001b[0m learner_conv\u001b[38;5;241m.\u001b[39mparam\u001b[38;5;241m.\u001b[39mcreate_report(learner_conv\u001b[38;5;241m.\u001b[39mmodel_addr)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mlearner_conv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 51\u001b[0m, in \u001b[0;36mLearnModel.train\u001b[1;34m(self, epoch_log, batch_log, overwrite)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Training Model\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_log\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch_log:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 95\u001b[0m, in \u001b[0;36mLearnModel.train_epoch\u001b[1;34m(self, optimizer, scheduler, batch_log)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Back Propagation\u001b[39;00m\n\u001b[0;32m     94\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 95\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam\u001b[38;5;241m.\u001b[39mgrad_clip)\n\u001b[0;32m     97\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\ris04\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ris04\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_conv = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes = 2,\n",
    "                                                                  trainable_backbone_layers = 5)\n",
    "model_conv = model_conv.to(device)\n",
    "learner_conv = LearnModel(model_conv, 'frcnn', addr.model_frcnn, data, param, device=device)\n",
    "learner_conv.param.create_report(learner_conv.model_addr)\n",
    "learner_conv.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
