{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ris04\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch.cuda, torch.utils.data, torch.nn, torch.optim, torch\n",
    "import torchvision.transforms, torchvision.datasets.folder, torchvision.utils, torchvision.models\n",
    "import transformers\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addresses\n",
    "\n",
    "class Address:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Stores all the addresses used in project\n",
    "        '''\n",
    "        # Inputs\n",
    "        self.data = \"../input/mammography\"\n",
    "        self.processed_data = \"data.pkl\"\n",
    "\n",
    "        # Coco\n",
    "        self.coco = os.path.join(self.data, 'coco_1k')\n",
    "        self.coco_annot = os.path.join(self.coco, 'annotations')\n",
    "        self.coco_annot_train = os.path.join(self.coco_annot, 'instances_train2017.json')\n",
    "        self.coco_annot_val = os.path.join(self.coco_annot, 'instances_val2017.json')\n",
    "        self.coco_img_train = os.path.join(self.coco, 'train2017')\n",
    "        self.coco_img_val = os.path.join(self.coco, 'val2017')\n",
    "\n",
    "        # Test\n",
    "        self.test = os.path.join(self.data, 'test')\n",
    "        self.test_img = os.path.join(self.test, 'images')\n",
    "        self.test_label = os.path.join(self.test, 'labels')\n",
    "        self.predictions = os.path.join(self.test, 'predictions')\n",
    "\n",
    "        # Yolo\n",
    "        self.yolo = os.path.join(self.data, 'yolo_1k')\n",
    "        self.yolo_train = os.path.join(self.yolo, 'train')\n",
    "        self.yolo_train_img = os.path.join(self.yolo_train, 'images')\n",
    "        self.yolo_train_label = os.path.join(self.yolo_train, 'labels')\n",
    "        self.yolo_val = os.path.join(self.yolo, 'val')\n",
    "        self.yolo_val_img = os.path.join(self.yolo_val, 'images')\n",
    "        self.yolo_val_labels = os.path.join(self.yolo_val, 'labels')\n",
    "\n",
    "        # Models\n",
    "        self.result = \"results/\"\n",
    "        self.model_frcnn = os.path.join(self.result, 'frcnn')\n",
    "        self.model_def_detr = os.path.join(self.result, 'deformable_dtr')\n",
    "\n",
    "        # Temp\n",
    "        self.temp = \"temp/\"\n",
    "\n",
    "    def create_dir(self, dir_list = None):\n",
    "        '''\n",
    "        Function to create directories in dir_list. If dir_list is None then create all directories of address.\n",
    "        '''\n",
    "        if dir_list == None:\n",
    "            dir_list = [self.temp, self.result, self.model_frcnn, self.model_def_detr]\n",
    "        for address in dir_list:\n",
    "            if not os.path.exists(address):\n",
    "                os.mkdir(address)\n",
    "\n",
    "    def _delete_folder_content(self, folder_addr):\n",
    "        '''\n",
    "        Deletes all the content of folder_addr\n",
    "        '''\n",
    "        if os.path.exists(folder_addr):\n",
    "            for file in os.listdir(folder_addr):\n",
    "                address = os.path.join(folder_addr, file)\n",
    "                if os.path.isdir(address):\n",
    "                    self._delete_folder_content(address)\n",
    "                    os.removedirs(address)\n",
    "                else:\n",
    "                    os.remove(address)\n",
    "\n",
    "    def clean(self, file_list = None):\n",
    "        '''\n",
    "        Deletes all the content in file_list\n",
    "        '''\n",
    "        if file_list == None:\n",
    "            file_list = [self.temp]\n",
    "        for address in file_list:\n",
    "            self._delete_folder_content(address)\n",
    "\n",
    "addr = Address()\n",
    "addr.clean()\n",
    "# addr.clean([addr.result])\n",
    "addr.create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Stores all Hyperparameters used for training of model\n",
    "        '''\n",
    "        # Training\n",
    "        self.batch_size = 2\n",
    "        self.num_epoch = 10\n",
    "        self.grad_clip = 1.0\n",
    "\n",
    "        # Data\n",
    "        self.num_train = 40000\n",
    "        self.num_val = 10000\n",
    "        self.train_step = self.num_epoch*(self.num_train//self.batch_size)\n",
    "        self.resolution = (512, 1024)\n",
    "        \n",
    "        # Learning Rate\n",
    "        self.lr = 1e-5\n",
    "        self.warmup_step = self.train_step//40\n",
    "        self.decay_step = self.train_step//2\n",
    "        self.decay_rate = 0.5\n",
    "\n",
    "    def lr_schedule(self, step):\n",
    "        '''\n",
    "        Getting learning rate as function of train steps completed (Exponential decay with linear warmup)\n",
    "        '''\n",
    "        if step <= self.warmup_step:\n",
    "            return step/self.warmup_step\n",
    "        else:\n",
    "            return self.decay_rate**((step-self.warmup_step)/self.decay_step)\n",
    "\n",
    "    def create_report(self, addr):\n",
    "        with open(os.path.join(addr, 'param.txt'), 'w') as file:\n",
    "            file.writelines([\n",
    "                f'Training:',\n",
    "                f'\\n\\tBatch Size:       {self.batch_size}',\n",
    "                f'\\n\\tNum Epoch:        {self.num_epoch}',\n",
    "                f'\\n\\tGrad Clip:        {self.grad_clip}',\n",
    "                f'\\n\\nData:',  \n",
    "                f'\\n\\tNum Train:        {self.num_train}',\n",
    "                f'\\n\\tNum Val:          {self.num_val}',\n",
    "                f'\\n\\tTrain Step:       {self.train_step}',\n",
    "                f'\\n\\tResolution:       {self.resolution}',\n",
    "                f'\\n\\nLearning Rate:',  \n",
    "                f'\\n\\tlr:               {self.lr}',\n",
    "                f'\\n\\tWarmup Step:      {self.warmup_step}',\n",
    "                f'\\n\\tDecay Step:       {self.decay_step}',\n",
    "                f'\\n\\tDecay Rate:       {self.decay_rate}',\n",
    "            ])\n",
    "\n",
    "param = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with device cpu\n"
     ]
    }
   ],
   "source": [
    "# Random Seed and CUDA\n",
    "\n",
    "random_seed = 68\n",
    "device = \"cpu\"\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed_all(random_seed)\n",
    "#     device = \"cuda\"\n",
    "print(f\"Working with device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, resolution, address_img, address_annot=None):\n",
    "        '''\n",
    "        Creates Dataset of images on given address.\n",
    "        '''\n",
    "        self.address_img = address_img\n",
    "        self.resolution = resolution\n",
    "        self.img_list = sorted(os.listdir(self.address_img))\n",
    "        self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                        torchvision.transforms.Resize(resolution, antialias=False)])\n",
    "        self.img_list = None\n",
    "        self.img_name_list = sorted(os.listdir(self.address_img))\n",
    "        with open(address_annot, 'rb') as file:\n",
    "            self.annotation = json.load(file)\n",
    "        self.beautify()\n",
    "        self.remove_empty()\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.img_list is None:\n",
    "            return len(self.img_name_list)\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.img_list is None:\n",
    "            img_addr = os.path.join(self.address_img, self.img_name_list[idx])\n",
    "            img = torchvision.datasets.folder.default_loader(img_addr)\n",
    "            return self.transform(img).to(torch.float), self.annotation[idx]\n",
    "        return self.img_list[idx], self.annotation[idx]\n",
    "    \n",
    "    def load(self):\n",
    "        '''\n",
    "        Loads all the data in RAM\n",
    "        '''\n",
    "        if self.img_list is not None:\n",
    "            return\n",
    "        self.img_list = [self[idx][0] for idx in range(len(self))]\n",
    "\n",
    "    def clean(self):\n",
    "        '''\n",
    "        Removes Data from RAM\n",
    "        '''\n",
    "        del self.img_list\n",
    "        self.img_list = None\n",
    "\n",
    "    def beautify(self):\n",
    "        '''\n",
    "        Removes Redundant data from json file\n",
    "        '''\n",
    "        label_data = {}\n",
    "        for img_data in self.annotation['images']:\n",
    "            label_data[img_data['id']] = img_data\n",
    "            label_data[img_data['id']]['bbox'] = []\n",
    "        for img_data in self.annotation['annotations']:\n",
    "            label_data[img_data['id']]['bbox'].append(img_data['bbox'])\n",
    "            img_data['bbox'][2] += img_data['bbox'][0]\n",
    "            img_data['bbox'][3] += img_data['bbox'][1]\n",
    "            img_data['bbox'][0] = img_data['bbox'][0]*self.resolution[0]/label_data[img_data['id']]['width']\n",
    "            img_data['bbox'][1] = img_data['bbox'][1]*self.resolution[1]/label_data[img_data['id']]['height']\n",
    "            img_data['bbox'][2] = img_data['bbox'][2]*self.resolution[0]/label_data[img_data['id']]['width']\n",
    "            img_data['bbox'][3] = img_data['bbox'][3]*self.resolution[1]/label_data[img_data['id']]['height']\n",
    "        self.annotation = sorted(label_data.values(), key = lambda data: data['file_name'])\n",
    "\n",
    "    def remove_empty(self):\n",
    "        img_list = []\n",
    "        img_name_list = []\n",
    "        annotation = []\n",
    "        for i in range(len(self.annotation)):\n",
    "            if len(self.annotation[i]['bbox']):\n",
    "                if self.img_list is not None:\n",
    "                    img_list.append(self.img_list[i])\n",
    "                annotation.append(self.annotation[i])\n",
    "                img_name_list.append(self.img_name_list[i])\n",
    "        if self.img_list is not None:\n",
    "            self.img_list = img_list\n",
    "        self.annotation = annotation\n",
    "        self.img_name_list = img_name_list\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, address: Address, param: HyperParameters):\n",
    "        '''\n",
    "        Creates DataLoader and DataSet for both train and val split\n",
    "        '''\n",
    "        self.address = address\n",
    "        self.param = param\n",
    "\n",
    "        # Dataset\n",
    "        self.dataset_train = DataSet(param.resolution, address.coco_img_train, address.coco_annot_train)\n",
    "        self.dataset_val = DataSet(param.resolution, address.coco_img_val, address.coco_annot_val)\n",
    "\n",
    "        # DataLoader\n",
    "        self.loader_train = torch.utils.data.DataLoader(self.dataset_train, batch_size=param.batch_size, collate_fn=self.collate, shuffle=True)\n",
    "        self.loader_val = torch.utils.data.DataLoader(self.dataset_val, batch_size=param.batch_size, collate_fn=self.collate, shuffle=False)\n",
    "    \n",
    "    def collate(self, batch):\n",
    "        label = []\n",
    "        img = []\n",
    "        for elem in batch:\n",
    "            img.append(elem[0].to(device))\n",
    "            if elem[1]['bbox']:\n",
    "                label_elem = {'boxes': torch.tensor(elem[1]['bbox'], dtype=torch.float, device=device), \n",
    "                              'labels': torch.tensor([0]*len(elem[1]['bbox']), dtype=torch.int64, device=device)}\n",
    "            else:\n",
    "                label_elem = {'boxes': torch.tensor([], dtype=torch.float, device=device).reshape(0, 4),\n",
    "                              'labels': torch.tensor([], dtype=torch.int64, device=device).reshape(0)}\n",
    "            label.append(label_elem)\n",
    "    \n",
    "        return img, label\n",
    "\n",
    "    def load(self):\n",
    "        '''\n",
    "        Loads all the data in RAM\n",
    "        '''\n",
    "        start_time = time.time()\n",
    "        self.dataset_train.load()\n",
    "        self.dataset_val.load()\n",
    "        print('Data Loaded in time:', time.time()-start_time)\n",
    "\n",
    "    def clean(self):\n",
    "        '''\n",
    "        Loads all the data in RAM\n",
    "        '''\n",
    "        self.dataset_train.clean()\n",
    "        self.dataset_val.clean()\n",
    "\n",
    "data = Data(addr, param)\n",
    "data.dataset_train.remove_empty()\n",
    "# data.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Model\n",
    "class LearnModel:\n",
    "    def __init__(self, model: torch.nn.Module, mtype, model_addr, data=data, param=param, device=device):\n",
    "        '''\n",
    "        Train, Evaluate and Predict\n",
    "        '''\n",
    "        \n",
    "        self.data = data\n",
    "        self.param = param\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.model_addr = model_addr\n",
    "        self.mtype = mtype\n",
    "\n",
    "        # Addresses\n",
    "        self.loss_addr = os.path.join(self.model_addr, 'loss.npz')\n",
    "        self.epoch_addr = lambda epoch: os.path.join(self.model_addr, f'model/{epoch}.pth')\n",
    "        self.scheduler_addr = lambda epoch: os.path.join(self.model_addr, f'scheduler/{epoch}.pth')\n",
    "        addr.create_dir([os.path.join(self.model_addr, 'model'),\n",
    "                         os.path.join(self.model_addr, 'scheduler')])\n",
    "\n",
    "    def train(self, epoch_log = True, batch_log = True, overwrite = False):\n",
    "        optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.param.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = self.param.lr_schedule)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Loss arr\n",
    "        if os.path.exists(self.loss_addr):\n",
    "            loss_arr = np.load(self.loss_addr)\n",
    "            train_loss_arr = list(loss_arr['train'])\n",
    "            val_loss_arr = list(loss_arr['val'])\n",
    "        else:\n",
    "            train_loss_arr = []\n",
    "            val_loss_arr = []\n",
    "\n",
    "        if overwrite:\n",
    "            addr.clean([self.model_addr])\n",
    "        \n",
    "        for epoch in range(self.param.num_epoch):\n",
    "            epoch_addr = self.epoch_addr(epoch)\n",
    "            scheduler_addr = self.scheduler_addr(epoch)\n",
    "\n",
    "            # Loading Model if present\n",
    "            if os.path.exists(epoch_addr) and os.path.exists(scheduler_addr):\n",
    "                self.model.load_state_dict(torch.load(epoch_addr), strict=False)\n",
    "                scheduler.load_state_dict(torch.load(scheduler_addr))\n",
    "                print(f\"Loaded model and scheduler at epoch {epoch}\")\n",
    "                continue\n",
    "\n",
    "            # Training Model\n",
    "            train_loss = self.train_epoch(optimizer, scheduler, batch_log=batch_log)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Validating Model\n",
    "            val_loss = self.validate_epoch(self.data.loader_val, batch_log=False)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tVal Loss: {val_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Saving data\n",
    "            train_loss_arr.append(train_loss)\n",
    "            val_loss_arr.append(val_loss)\n",
    "            np.savez_compressed(self.loss_addr, train=np.array(train_loss_arr), val=np.array(val_loss_arr))     # Saving Loss Array\n",
    "            torch.save(self.model.state_dict(), epoch_addr)     # Saving Model\n",
    "            torch.save(scheduler.state_dict(), scheduler_addr)  # Saving Scheduler\n",
    "\n",
    "            # Printing blank line between each epoch in Log\n",
    "            if epoch_log:\n",
    "                print()\n",
    "        \n",
    "    def train_epoch(self, optimizer, scheduler, batch_log):\n",
    "        '''\n",
    "        Trains model for one epoch\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        dataloader = self.data.loader_train\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.train()          # Set Model to train Mode\n",
    "\n",
    "        for data in dataloader:\n",
    "            # Copying data to cuda\n",
    "            x, y = data\n",
    "\n",
    "            # Forward Propagation\n",
    "            loss_dict = self.model(x, y)\n",
    "\n",
    "            # Computing Loss\n",
    "            loss = sum(loss_dict.values())\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Back Propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.param.grad_clip)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update batch count\n",
    "            batch_ct += 1\n",
    "\n",
    "            if batch_log and batch_ct%25 == 0:\n",
    "                print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "    \n",
    "    def validate_epoch(self, dataloader, batch_log):\n",
    "        '''\n",
    "        Calculates Loss on data in given dataloader\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.eval()           # Set Model to eval mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Copying data to cuda\n",
    "                x, y = data\n",
    "\n",
    "                # Forward Propagation\n",
    "                output_dict = self.model(x)\n",
    "                for i in range(len(output_dict)):\n",
    "                    if output_dict[i]['boxes'].shape[0]:\n",
    "                        print(output_dict[i], y[i])\n",
    "\n",
    "                # Update batch count\n",
    "                batch_ct += 1\n",
    "\n",
    "                if batch_log and batch_ct%25 == 0:\n",
    "                    print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "\n",
    "    def plot_loss(self, addr = None):\n",
    "        '''\n",
    "        Plots Loss vs number of epochs\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        train_arr, val_arr = loss_arr['train'], loss_arr['val']\n",
    "        num_epoch = train_arr.shape[0]\n",
    "        x_arr = np.linspace(1, num_epoch, num_epoch)\n",
    "\n",
    "        if addr is None:\n",
    "            addr = os.path.join(self.model_addr, 'loss_curve')\n",
    "\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"MSE Loss\")\n",
    "        plt.plot(x_arr, train_arr, label='Train')\n",
    "        plt.plot(x_arr, val_arr, label='Val')\n",
    "        plt.legend()\n",
    "        plt.savefig(addr)\n",
    "\n",
    "    def best_model(self):\n",
    "        '''\n",
    "        Returns Best Model as well as changes self.model in place to best model\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        best_epoch = np.argmin(loss_arr['val'])\n",
    "        self.model.load_state_dict(torch.load(self.epoch_addr(best_epoch)), strict=False)\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# model_conv = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes = 2,\n",
    "#                                                                   trainable_backbone_layers = 5)\n",
    "# model_conv = model_conv.to(device)\n",
    "# learner_conv = LearnModel(model_conv, 'frcnn', addr.model_frcnn, data, param, device=device)\n",
    "# learner_conv.param.create_report(learner_conv.model_addr)\n",
    "# learner_conv.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ris04\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ris04\\.cache\\huggingface\\hub\\models--facebook--deformable-detr-box-supervised. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ris04\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Deformable DETR model\n",
    "model_name = \"facebook/deformable-detr-box-supervised\"\n",
    "config = transformers.DeformableDetrConfig.from_pretrained(model_name)\n",
    "image_processor = transformers.DeformableDetrImageProcessor.from_pretrained(model_name)\n",
    "model_detr = transformers.DeformableDetrForObjectDetection.from_pretrained(model_name).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
